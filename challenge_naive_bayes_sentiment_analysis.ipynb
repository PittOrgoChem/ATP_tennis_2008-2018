{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHALLENGE: Sentiment Analysis and Naive Bayes\n",
    "\n",
    "## By Jean-Philippe Pitteloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The working dataset was selected from data available on the University of California Irvine Machine Learning Repository (https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences#). A group of files were manually downloaded and the \"Yelp\" (yelp_labelled.txt) dataset for the model was selected responding to personal interests. The data from the downloaded file was read as a Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_raw = pd.read_csv('yelp_labelled.txt', delimiter= '\\t', header=None)\n",
    "yelp_raw.columns = ['sentence', 'score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>As for the service, I thought it was good.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>Will never, ever go back.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>The best place to go for a tasty bowl of Pho!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>I swung in to give them a try but was deeply d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>Seriously killer hot chai latte.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>OMG, the food was delicioso!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>The worst was the salmon sashimi.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>He also came back to check on us regularly, ex...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>Thoroughly disappointed!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>My side Greek salad with the Greek dressing wa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence  score\n",
       "729         As for the service, I thought it was good.      1\n",
       "306                          Will never, ever go back.      0\n",
       "195      The best place to go for a tasty bowl of Pho!      1\n",
       "576  I swung in to give them a try but was deeply d...      0\n",
       "888                   Seriously killer hot chai latte.      1\n",
       "338                       OMG, the food was delicioso!      1\n",
       "29                   The worst was the salmon sashimi.      0\n",
       "573  He also came back to check on us regularly, ex...      1\n",
       "509                           Thoroughly disappointed!      0\n",
       "49   My side Greek salad with the Greek dressing wa...      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_raw.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Responding to our interest of creating a model to evaluate sentiments in text and produce a score in terms of \"positive\" or \"negative\" sentiment, the first step was to simplify the format of the text available by removing special characters and turning every letter in the text to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_raw['sentence'] = yelp_raw['sentence'].str.lower().str.replace(r'[,.!]+', ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get a sense of which words are more commonly found in both \"positive\" and \"negative\" comments/reviews, all comments in every group of reviews were splitted in their composing words and the count of words was summarized from most common to least common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pos_words = pd.Series(' '.join(yelp_raw[yelp_raw['score'] == 1]['sentence']).lower().split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_words = pd.Series(' '.join(yelp_raw[yelp_raw['score'] == 0]['sentence']).lower().split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common words in Positive comments:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "              698\n",
       "the           310\n",
       "and           222\n",
       "was           138\n",
       "i             117\n",
       "a             112\n",
       "is            104\n",
       "to             87\n",
       "this           77\n",
       "good           73\n",
       "great          70\n",
       "food           60\n",
       "in             59\n",
       "place          57\n",
       "of             53\n",
       "it             51\n",
       "very           47\n",
       "service        45\n",
       "for            43\n",
       "with           42\n",
       "had            37\n",
       "are            36\n",
       "so             35\n",
       "we             34\n",
       "were           34\n",
       "you            34\n",
       "have           33\n",
       "my             33\n",
       "on             32\n",
       "they           32\n",
       "here           29\n",
       "all            25\n",
       "friendly       24\n",
       "that           24\n",
       "delicious      23\n",
       "back           23\n",
       "be             23\n",
       "best           22\n",
       "time           22\n",
       "our            22\n",
       "really         22\n",
       "nice           22\n",
       "amazing        21\n",
       "but            20\n",
       "their          19\n",
       "not            18\n",
       "just           18\n",
       "as             18\n",
       "also           18\n",
       "restaurant     17\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Most common words in Positive comments:\\n')\n",
    "pos_words.value_counts()[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common words in Negative comments:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "           674\n",
       "the        274\n",
       "i          187\n",
       "and        169\n",
       "was        157\n",
       "to         131\n",
       "a          125\n",
       "not         98\n",
       "it          82\n",
       "of          74\n",
       "is          67\n",
       "for         67\n",
       "this        66\n",
       "food        65\n",
       "place       49\n",
       "in          48\n",
       "we          45\n",
       "be          44\n",
       "that        43\n",
       "but         42\n",
       "at          40\n",
       "my          39\n",
       "back        38\n",
       "service     37\n",
       "had         33\n",
       "so          31\n",
       "with        30\n",
       "like        29\n",
       "very        29\n",
       "were        29\n",
       "have        29\n",
       "here        28\n",
       "there       28\n",
       "go          26\n",
       "are         26\n",
       "you         25\n",
       "they        24\n",
       "no          23\n",
       "on          23\n",
       "good        22\n",
       "don't       22\n",
       "will        22\n",
       "never       22\n",
       "would       21\n",
       "time        20\n",
       "if          20\n",
       "minutes     19\n",
       "our         19\n",
       "ever        19\n",
       "bad         18\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Most common words in Negative comments:\\n')\n",
    "neg_words.value_counts()[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going through the lists of words displayed above, a list of keywords associated to both positive and negative comments was created and new features in our working dataset, indicating the presence or absence of the keywords in a given comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_keywords = ['good', 'great', 'friendly', 'delicious', 'nice', 'best', 'amazing', 'like', 'love', 'fantastic', 'awesome', 'pretty', 'loved', 'excellent', 'tasty', 'recommend', 'fresh', 'not', 'bad', 'terrible', 'worst', 'disgusting', 'never', 'won\"t', 'dissapointed', 'dissapointing']\n",
    "\n",
    "for word in pos_keywords:\n",
    "    yelp_raw[str(word)] = yelp_raw['sentence'].str.contains(str(word), case=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The working dataframe was splitted into two new dataframes. The 'data' dataset contained all new features created associated to the selecte keywords, while the 'target' dataset contain only the values associated to the score received by the original comment in terms of \"positive\" or \"negative\" sentiment associated to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = yelp_raw[pos_keywords]\n",
    "target = yelp_raw['score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last, the necessary requirements were imported to apply a Naive Bayes Bernoulli classification model and the model executed using the two new datasets created above ('data' and 'target'). Once the model was built, the model was used to predict scores/values and its performance compared to the scores assigned in the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 1000 points : 242\n"
     ]
    }
   ],
   "source": [
    "# Our data is binary / boolean, so we're importing the Bernoulli classifier.\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# Instantiate our model and store it in a new variable.\n",
    "model_bnb = BernoulliNB()\n",
    "\n",
    "# Fit our model to the data.\n",
    "model_bnb.fit(data, target)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred = model_bnb.predict(data)\n",
    "\n",
    "# Display our results.\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\".format(data.shape[0], (target != y_pred).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen above, our classification model successfully classified 758 (76%) from the 1000 comments available in the dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application of the classification model to the IMDb dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order test the appicability of our model in a dataset containing sentiment-related comments/reviews collected by a different industry, the model was tested in a dataset obtained on the same repository mentioned at the beginning of this work, but including movie and shows reviews from the website IMDb (imdb_labelled.txt). First the dataset was read into a Pandas dataframe and appropriately formatted and prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_raw = pd.read_csv('imdb_labelled.txt', delimiter= '\\t', header=None)\n",
    "imdb_raw.columns = ['sentence', 'score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A very, very, very slow-moving, aimless movie ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not sure who was more lost - the flat characte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very little music or anything to speak of.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The best scene in the movie was when Gerardo i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  score\n",
       "0  A very, very, very slow-moving, aimless movie ...      0\n",
       "1  Not sure who was more lost - the flat characte...      0\n",
       "2  Attempting artiness with black & white and cle...      0\n",
       "3       Very little music or anything to speak of.        0\n",
       "4  The best scene in the movie was when Gerardo i...      1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_raw['sentence'] = imdb_raw['sentence'].str.lower().str.replace(r'[,.!]+', ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the comments were formatted, a search of each keyword in the list created for our previous model was performed on the new dataset and features created to record the presence or absence of a given keyword in the comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_keywords = ['good', 'great', 'friendly', 'delicious', 'nice', 'best', 'amazing', 'like', 'love', 'fantastic', 'awesome', 'pretty', 'loved', 'excellent', 'tasty', 'recommend', 'fresh', 'not', 'bad', 'terrible', 'worst', 'disgusting', 'never', 'won\"t', 'dissapointed', 'dissapointing']\n",
    "\n",
    "for word in pos_keywords:\n",
    "    imdb_raw[str(word)] = imdb_raw['sentence'].str.contains(str(word), case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_imdb = imdb_raw[pos_keywords]\n",
    "target_imdb = imdb_raw['score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data from the dataset was then fed into the model to generate predictions, and the predictions compared to the scores present in the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 748 points : 291\n"
     ]
    }
   ],
   "source": [
    "# Classify, storing the result in a new variable.\n",
    "y_pred_imdb = model_bnb.predict(data_imdb)\n",
    "\n",
    "# Display our results.\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\".format(data_imdb.shape[0], (target_imdb != y_pred_imdb).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen above, our model (prepared using data from food/restaurant reviews) successfully predicted the score for 457 (61%) from the 748 reviews available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application of the classification model to the Amazon dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the appicability of our model in a dataset containing sentiment-related comments/reviews collected by Amazon. As described in the previous section, our classification model was built using food/restaurant reviews from the website YELP. In this section, a Pandas dataframe was created using information contained in the amazon_cells_labelled.txt file manually downloaded from the University of California Irvine Machine Learning Repository (https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the dataframe was created and the columns formatted appropriately to run our working model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_raw = pd.read_csv('amazon_cells_labelled.txt', delimiter= '\\t', header=None)\n",
    "amazon_raw.columns = ['sentence', 'score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  score\n",
       "0  So there is no way for me to plug it in here i...      0\n",
       "1                        Good case, Excellent value.      1\n",
       "2                             Great for the jawbone.      1\n",
       "3  Tied to charger for conversations lasting more...      0\n",
       "4                                  The mic is great.      1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_raw['sentence'] = amazon_raw['sentence'].str.lower().str.replace(r'[,.!]+', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_keywords = ['good', 'great', 'friendly', 'delicious', 'nice', 'best', 'amazing', 'like', 'love', 'fantastic', 'awesome', 'pretty', 'loved', 'excellent', 'tasty', 'recommend', 'fresh', 'not', 'bad', 'terrible', 'worst', 'disgusting', 'never', 'won\"t', 'dissapointed', 'dissapointing']\n",
    "\n",
    "for word in pos_keywords:\n",
    "    amazon_raw[str(word)] = amazon_raw['sentence'].str.contains(str(word), case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_amazon = amazon_raw[pos_keywords]\n",
    "target_amazon = amazon_raw['score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the dataset appropriately formatted for the modeling stage, our working model was employed to predict the \"sentiment\" associated with a given review, and the performance of the model evaluated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 1000 points : 266\n"
     ]
    }
   ],
   "source": [
    "# Classify, storing the result in a new variable.\n",
    "y_pred_amazon = model_bnb.predict(data_amazon)\n",
    "\n",
    "# Display our results.\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\".format(data_amazon.shape[0], (target_amazon != y_pred_amazon).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results above, our working model succesfully predicted the \"sentiment\" of only 734 (73%) of the 1000 reviews available in the Amazon dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be concluded that while the selection of keywords made to built our model succesfully classified the majority of reviews in all three datasets employed, a more robust model may be required to be able to accurately predict the \"sentiment\" of comments/reviews in a general context"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
